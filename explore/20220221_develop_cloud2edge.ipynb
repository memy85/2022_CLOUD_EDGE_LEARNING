{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "- This notebook is to transfer the codes developed by Tae to pytorch codes and some practical codes that can be used in real learning simulations.\n",
    "- This code assumes real distributed environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom Network or Server Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Concatenate,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class BottomNetwork(object):\n",
    "    def __init__(self, config):\n",
    "        self.task: str = config['task']\n",
    "        self.bottom_input_size: int = config['bottom_input_size']\n",
    "        self.layers: int = config['layers']\n",
    "        self.hidden_units: int = config['hidden_units']\n",
    "        self.random_seed: int = config['random_seed']\n",
    "        self.bottom_network: Model = None # create_bottom_network\n",
    "        self.bottom_weights_grads: tf.Tensor = None # bottom_split_gradients\n",
    "\n",
    "    def create_bottom_network(self):\n",
    "        input_layer = Input(shape=self.bottom_input_size, name=\"bottom_input\")\n",
    "        dense = input_layer\n",
    "        for i in range(self.layers):\n",
    "            dense = Dense(\n",
    "                units=self.hidden_units,\n",
    "                kernel_initializer=glorot_uniform(seed=self.random_seed),\n",
    "                activation='relu',\n",
    "                name='bottom_dense_{}'.format(i + 1)\n",
    "            )(dense)\n",
    "        self.bottom_network = Model(input_layer, dense, name=f\"{self.task}_bottom_model\")\n",
    "        return self.bottom_network\n",
    "\n",
    "    def bottom_split_gradients(self, bottom_input: np.ndarray, h_grad_from_top: tf.Tensor):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            bottom_input_tf = tf.constant(bottom_input)\n",
    "            bottom_weights = self.bottom_network.trainable_weights\n",
    "            tape.watch(bottom_input_tf)\n",
    "            tape.watch(bottom_weights)\n",
    "            h = self.bottom_network(bottom_input) # TODO h 두 번 계산됨. self에 넣고. bottom class 계산 --> Top Network에 전달?\n",
    "        self.bottom_weights_grads = tape.gradient(h, bottom_weights, output_gradients=h_grad_from_top)\n",
    "        return self.bottom_weights_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../cloud2edge/utils/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile ../cloud2edge/utils/__init__.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../cloud2edge/configurer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../cloud2edge/configurer.py\n",
    "\n",
    "\n",
    "class Configurer:\n",
    "    def __init__(self, task, server_input_size, layers, hidden_units, random_seed):\n",
    "        self.task = task:str\n",
    "        self.server_input_size = server_input_size\n",
    "        self.hidden_units = hidden_units\n",
    "        self.random_seed = random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud2edge/models/server/server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../cloud2edge/models/server/server.py\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class ServerNetwork:\n",
    "    def __init__(self, config_object):\n",
    "        self.task: str = config_object.task\n",
    "        self.server_input_size = config_object.server_input_size\n",
    "        self.layers = config_object.layers\n",
    "        self.hidden_units = config_object.hidden_units\n",
    "        self.random_seed = config_object.random_seed\n",
    "        \n",
    "        self.block_list = OrderedDict()\n",
    "        \n",
    "        self.server_network = None # create server network \n",
    "    \n",
    "    def create_server_network(self):\n",
    "        self.server_input_layer = nn.Linear(self.server_input_size, self.hidden_units)\n",
    "        \n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            \n",
    "            self.block_list[str(idx)] = nn.Sequential(\n",
    "                        nn.Linear(self.hidden_units, self.hidden_units),\n",
    "                        nn.ReLU()\n",
    "                        )\n",
    "        return nn.Sequential(self.server_input_layer,\n",
    "                            *self.block_list)\n",
    "    \n",
    "    def server_split_gradients(self, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6c9a2cf001b27c783973244b75638e1d3638859eeadef0c40fd3269e28570fa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('2022_edge_cloud_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
